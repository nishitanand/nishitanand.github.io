---
layout: about
title: about
permalink: /

profile:
  align: right
  image: prof_pic.jpg
  image_circular: true # crops the image to make it circular


news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: false  # includes social icons at the bottom of the page
---

My name is Nishit Anand. I am a first-year MS CS student at the [University of Maryland, College Park](https://www.cs.umd.edu/). I do research on Computer Vision, Audio and Multimodal LLMs, particularly Foundation Multimodal Models under the guidance of [Prof. Dinesh Manocha](https://www.cs.umd.edu/people/dmanocha) in the [GAMMA Lab](https://gamma.umd.edu/) at UMD.

Before this, I worked in the industry as a ML Scientist at [Radien](https://radien.app/), a Seattle-based AI startup funded by the Paul Allen Institiute for AI (AI2). I was the first ML hire in the team and built the ML pipeline of our product which helps front-end teams simplify their codebases using AI. There I worked on Vision-Language models, Code LLMs and on Image and Code Similarity for our product.

I also have experience as a Foundng ML Engineer at Ananas Labs, a LLM-focused startup based out of Bengaluru, founded by former Staff Research Scientist, Google Research India. There I built our Multilingual ML News product. I worked on Multilingual LLMs, News Article Summarization, Automatic Speech Recognition and Text-to-Speech. I also did research on LLM tokenization and building novel Multilingual LLMs.


I also have full-time research experience. Previously, I worked as a Research Assistant at the [Vision and Graphics Lab](https://vision-iitd.github.io/), Indian Institute of Technology Delhi (IIT Delhi) under [Prof. Chetan Arora](https://www.cse.iitd.ac.in/~chetan/). I worked on a Govt. of India funded project, where I created State-of-The-Art ViT-based OCR ML models for 14 official Indian languages, covering both Printed and Scene-Text modalities. I conducted research on long-context Line-Level OCR (Optical Character Recognition) as well. 

Before that, I worked at the Autonomous Networked Systems Lab (Vision Lab) at Indraprastha Institute of Information Technology Delhi (IIIT-Delhi) under [Prof. Saket Anand](https://www.iiitd.ac.in/anands). At IIITD, I worked on the [ALIVE Project](https://sites.google.com/iiitd.ac.in/iiitd-alive/home) (Autonomous Last mILe VEhicle), an autonomous driving project funded by the Ministry of Electronics and Information Technology, Govt. of India. I led the Driver Status Monitoring (DSM) module of the ALIVE project, where I  created a Facial Landmark Detection ML model for predicting drowsiness and attentiveness of an autonomous vehicle driver. 

I completed my B.Tech (Honours) in Computer Science from Jaypee Institute of Information Technology Noida ([JIIT Noida](https://www.jiit.ac.in/)) in 2022. I graduated in the top 5 percentile of the CS Department and scored the highest in all courses in my final year.

CV: [Link](https://drive.google.com/file/d/1smmuLIqhT6LNsrDLECqP6akAVWGHrkr6/view)
Google Scholar: [Link](https://scholar.google.com/citations?hl=en&user=6bZx8DYAAAAJ&view_op=list_works&sortby=pubdate)

<!---
Write your biography here. Tell the world about yourself. Link to your favorite [subreddit](http://reddit.com). You can put a picture in, too. The code is already in, just name your picture `prof_pic.jpg` and put it in the `img/` folder.

Put your address / P.O. box / other info right below your picture. You can also disable any these elements by editing `profile` property of the YAML header of your `_pages/about.md`. Edit `_bibliography/papers.bib` and Jekyll will render your [publications page](/al-folio/publications/) automatically.

Link to your social media connections, too. This theme is set up to use [Font Awesome icons](http://fortawesome.github.io/Font-Awesome/) and [Academicons](https://jpswalsh.github.io/academicons/), like the ones below. Add your Facebook, Twitter, LinkedIn, Google Scholar, or just disable all of them.
-->
